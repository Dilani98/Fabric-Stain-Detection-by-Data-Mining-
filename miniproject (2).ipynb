{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec0ebUTTqYY5",
        "outputId": "bde551ac-ebf7-48c1-cd74-0d1fe907ee84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of stain images: 398\n",
            "Number of defect-free images: 68\n",
            "Image dimensions: (150, 150, 3)\n",
            "Mean Pixel Value: 166.10313991416308\n",
            "Standard Deviation of Pixel Value: 31.830945249282617\n",
            "Class Distribution: {'stain': 398, 'defect_free': 68}\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.4452 - accuracy: 0.8683 - val_loss: 0.5538 - val_accuracy: 0.7979\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 16s 1s/step - loss: 0.3976 - accuracy: 0.8683 - val_loss: 0.4955 - val_accuracy: 0.7979\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 17s 1s/step - loss: 0.4023 - accuracy: 0.8683 - val_loss: 0.5038 - val_accuracy: 0.7979\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 16s 1s/step - loss: 0.3983 - accuracy: 0.8683 - val_loss: 0.5431 - val_accuracy: 0.7979\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 16s 1s/step - loss: 0.4017 - accuracy: 0.8683 - val_loss: 0.6077 - val_accuracy: 0.7979\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 16s 1s/step - loss: 0.4010 - accuracy: 0.8683 - val_loss: 0.4978 - val_accuracy: 0.7979\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 15s 1s/step - loss: 0.3901 - accuracy: 0.8683 - val_loss: 0.5289 - val_accuracy: 0.7979\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 15s 1s/step - loss: 0.3894 - accuracy: 0.8683 - val_loss: 0.5039 - val_accuracy: 0.7979\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 16s 1s/step - loss: 0.3920 - accuracy: 0.8683 - val_loss: 0.4881 - val_accuracy: 0.7979\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 16s 1s/step - loss: 0.3930 - accuracy: 0.8683 - val_loss: 0.4876 - val_accuracy: 0.7979\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 0.4876 - accuracy: 0.7979\n",
            "Test Accuracy: 0.7978723645210266\n"
          ]
        }
      ],
      "source": [
        "# 1: Identifying Problem\n",
        "# Binary classification task to classify images into \"stain\" and \"defect-free\" categories.\n",
        "\n",
        "# 2: Data Understanding\n",
        "\n",
        "## Data Collection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = \"/content/drive/My Drive/miniproject_daminda_sir/dataset/images\"\n",
        "categories = [\"stain\", \"defect_free\"]\n",
        "image_size = (150, 150)\n",
        "\n",
        "annotation_dir = os.path.join(dataset_dir, \"annotation\")\n",
        "if os.path.exists(annotation_dir):\n",
        "    for file in os.listdir(annotation_dir):\n",
        "        os.remove(os.path.join(annotation_dir, file))\n",
        "    os.rmdir(annotation_dir)\n",
        "    print(\"Annotation folder and files removed successfully.\")\n",
        "\n",
        "## Data Exploration\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(dataset_dir, category)\n",
        "    label = categories.index(category)\n",
        "    for img_filename in os.listdir(category_path):\n",
        "        try:\n",
        "            img = cv2.imread(os.path.join(category_path, img_filename))\n",
        "            img = cv2.resize(img, image_size)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(\"Error loading image:\", e)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "num_stain_images = np.sum(labels == 0)\n",
        "num_defect_free_images = np.sum(labels == 1)\n",
        "image_dimensions \n",
        "= images.shape[1:]\n",
        "\n",
        "print(\"Number of stain images:\", num_stain_images)\n",
        "print(\"Number of defect-free images:\", num_defect_free_images)\n",
        "print(\"Image dimensions:\", image_dimensions)\n",
        "\n",
        "# Descriptive Analysis\n",
        "mean_pixel_value = np.mean(images)\n",
        "std_pixel_value = np.std(images)\n",
        "\n",
        "print(\"Mean Pixel Value:\", mean_pixel_value)\n",
        "print(\"Standard Deviation of Pixel Value:\", std_pixel_value)\n",
        "\n",
        "class_distribution = {category: np.sum(labels == categories.index(category)) for category in categories}\n",
        "print(\"Class Distribution:\", class_distribution)\n",
        "\n",
        "# 3: Data Preprocessing\n",
        "\n",
        "## Cleaning (Already done by removing the \"annotation\" folder)\n",
        "\n",
        "## Transformation\n",
        "images = images / 255.0\n",
        "\n",
        "# 4: Data Mining\n",
        "\n",
        "## Predictive Analysis\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=image_dimensions),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# 5: Evaluation and Interpretation\n",
        "\n",
        "## Results\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po47eWvkEvuu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfcmu1zrq0xF",
        "outputId": "781ba6d6-01b0-4d71-c653-8d0ef24921df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Save Keras model\n",
        "model.save(\"model_unquant.h5\")\n",
        "\n",
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save TFLite model to file\n",
        "with open(\"model_unquant.tflite\", \"wb\") as f:\n",
        "    f.write(model_tflite)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
